# Primary Config file for LDS Incremental settings. Typically we override this with a user config but this can be edited to be used as a template

[LDS]
#LDS settings since key incl though in generic WFS this could be ignored
url: http://wfs.data.linz.govt.nz/
key: cbfe37d440764cc1a8e6889e235d8c43
svc: WFS
ver: 1.0.0
fmt: GML2
cql:
 

[PostgreSQL]
host: 127.0.0.
port: 5432
dbname: ldsincr
schema: lds
user: pguser
pass: pgpass
overwrite: YES
epsg:
cql:
config: external


[MSSQLSpatial]
odbc:
server: <sql-server>\<SQLExpress>
dbname: <db-name>
schema: <db-schema/dbo?>
trust: no
user: 
pass:
epsg:
cql:
config: external


[SQLite]
file:
epsg:
cql:
config: external


[FileGDB]
file:
epsg:
cql:
config: external


[Proxy]
host:
port:
auth:
user:
pass:


[Misc]
#global variables
#global layer lists for special treatment

#SIXTYFOUR BIT LAYERS
#Enabled
#Identifies layers containing 64 bit integer fields requiring conversion to a string datatype. These need to be listed because WFS returns
#incorrectly truncated integers silently.

64bitlayers: 1203,1204,1205,1209,1028,1029

#PARTITION LAYERS 
#Not Enabled!
#Large layers (records>100,000) are not completely served over WFS. When manual (CQL based) partitioning is used we have to specify 
#which layers this applies to. Because these layers have to be sorted they must have a primary key.
#The partition size parameter is used for both manual and internal paging

#partitionlayers: 772,839,1029,817
partitionsize: 5000

#TEMPORARY TABLES
#Not Enabled!
#Decide the preferred format for the table where WFS results are stored and manipulated before saving to permanent storage. 
#Employing the GDAL layer copy mechanism instead of copying individual features can be enabled in the script. Doing this however
#makes column deletion difficult. Because deleting columns after copying can be space inefficient on some databases we can do this 
#using a temporary table. Below we specify the form of the temporary table to employ.  
#DIRECT doesn't use a temporary but because DB column deletes temporarily leave data in their respective tables you could end up with a replication database larger than you expected. 
#Memory is the fastest temp table method but requires RAM sufficient to handle the largest layer you want to download. 
#ESRI requires less memory but truncates 'long' column names so would be a problem when adding incremental updates with full column names. 
#Mapinfo, GeoJSON, GMT and AutoCAD DXF all have problems when deleting columns though future updates may change this.
#Currently supported {DIRECT, Memory, ESRI Shapefile, Mapinfo File, GeoJSON, GMT, DXF (AutoCAD DXF)}

temptable: Memory


