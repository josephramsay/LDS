# Primary Config file for LDS Incremental settings. Typically we override this with a user config but this can be edited to be used as a template

[LDS]
#LDS settings since key incl though in generic WFS this could be ignored
url: http://wfs.data.linz.govt.nz/
key: <your key here>
svc: WFS
ver: 1.0.0
fmt: GML2
cql:


[PostgreSQL]
host: <host-ip>
port: <pg-port>
dbname: <db-name>
schema: <db-schema>
user:
pass:
overwrite: YES
epsg:
cql:
config: external


[MSSQLSpatial]
odbc: SQL Server Native Client 11.0
#odbc: FreeTDS <when using linux driver>
server: <sql-server>\SQLExpress
dbname: <db-name>
schema: <db-schema/dbo?>
trust: yes
user: mssqluser
pass: mssqlpass
epsg:
cql:
config: internal


[SQLite]
path: ~/temp/spatialite
name: <slite-file>
epsg:
cql:
config: internal


[FileGDB]
path: ~/temp/filegdb
name: <fgdb-dir>
epsg:
cql:
config: internal


[Oracle]
#placeholder data, not tested
instance: <oracledb>
user: <user>
pass: <password>


[ArcSDE]
#placeholder data, not tested
server: <arcsde_server>
instance: <sql2008common>
database: <arcgis_spatial>
user: <domain>\<user>
pass: <password>


[File]
#catchalll for shapefile, mapinfo and csv
prefix: lds_
path: ~/temp/ldsfile/

[Misc]
#global variables
#global layer lists for special treatment

#64 bit layers identifies layers containing 64 bit integer fields requiring conversion to a string datatype
64bitlayers: 1203,1204,1205,1209,1028,1029

#Partition Layers. Large layers (records>100,000) are not completely served over WFS. Listing layers in this list 
#triggers feature-by-feature copying of data blocks delimited by range in the primary key. This is implemeneted in CQL
#and will typically take the form cql_filter=id between 0 and 9999. Note. Feature-by-feature copys, especially for 
#large layers, will be very slow.   
partitionlayers: 772,839,1029,817
partitionsize: 5000

#Temporary Table type. Decide the prefered format for the table where WFS results are stored and manipulated before saving to permanent storage.
#DIRECT doesn't use a temporary but because DB column deletes temporarily leave data in their respective tables you could end up with a replication database larger than you expected. 
#Memory is the fastest temp table method but requires RAM sufficient to handle the largest layer you want to download. 
#ESRI requires less memory but truncates 'long' column names so would be a problem when adding incremental updates with full column names. 
#Mapinfo, GeoJSON, GMT and AutoCAD DXF all have problems when deleting columns though future updates may change this.
#Currently supported {DIRECT, Memory, ESRI Shapefile, Mapinfo File, GeoJSON, GMT, DXF (AutoCAD DXF)}
temptable: Memory



